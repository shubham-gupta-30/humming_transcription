{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v82MkU2iqmM6"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi > /dev/null 2>&1\n",
        "!pip install librosa > /dev/null 2>&1\n",
        "!pip install noisereduce > /dev/null 2>&1\n",
        "!pip install tqdm > /dev/null 2>&1\n",
        "!pip install mir_eval > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import torch\n",
        "import librosa\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import noisereduce as nr\n",
        "from scipy import stats\n",
        "import scipy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from multiprocessing import Pool\n",
        "from tqdm import tqdm\n",
        "import mir_eval"
      ],
      "metadata": {
        "id": "7AjxmX-Zr8qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data loader (wav and midi files)\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, directory,json_file, subset, transform=None):\n",
        "        with open(directory+json_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        self.file_list = data[subset]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        audio_file = self.file_list[idx]\n",
        "        audio, sr = librosa.load(directory+\"wav_data_sync_with_midi/\"+audio_file+\".wav\", sr=None)\n",
        "        midi=pretty_midi.PrettyMIDI(directory+\"midi_data/\"+audio_file+\".mid\")\n",
        "\n",
        "        if self.transform:\n",
        "            audio = self.transform(audio)\n",
        "\n",
        "        return audio,sr,midi\n",
        "\n",
        "def get_notes(midi):\n",
        "    return np.array([note.pitch for note in midi.instruments[0].notes])"
      ],
      "metadata": {
        "id": "G_OXYGjYsFHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_onset_offset(midi):\n",
        "  onset,offset=[],[]\n",
        "  for instrument in midi.instruments:\n",
        "      for note in instrument.notes:\n",
        "          onset.append(note.start)  # onset time in seconds\n",
        "          offset.append(note.end)  # offset time in seconds\n",
        "  return np.vstack([onset,offset]).T"
      ],
      "metadata": {
        "id": "ovoYDyeARTNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_TOLERANCE = 0.05 #ONSET TOLERANCE\n",
        "OCTAVE_INVARIANT_RADIUS = 16\n",
        "\n",
        "\n",
        "def trim_midi(ref_midi_data, est_midi_data):\n",
        "    ref_notes = []\n",
        "    for i in ref_midi_data.instruments:\n",
        "        if i.is_drum:\n",
        "            continue\n",
        "        for n in i.notes:\n",
        "            ref_notes.append(n)\n",
        "    segment_start = ref_notes[0].start\n",
        "    segment_end = ref_notes[-1].end\n",
        "\n",
        "    num_dropped = 0\n",
        "    for i in est_midi_data.instruments:\n",
        "        if i.is_drum:\n",
        "            continue\n",
        "        i.notes = [\n",
        "            n for n in i.notes if n.start >= segment_start and n.start <= segment_end\n",
        "        ]\n",
        "\n",
        "    return est_midi_data\n",
        "\n",
        "\n",
        "def midi_to_mir_eval(midi_data, dummy_offsets = True):\n",
        "    notes = []\n",
        "    for i in midi_data.instruments:\n",
        "        if i.is_drum:\n",
        "            continue\n",
        "        for n in i.notes:\n",
        "            notes.append((n.start, n.end, n.pitch))\n",
        "    notes = sorted(notes)\n",
        "    note_onsets = [s for s, _, _ in notes]\n",
        "    note_offsets = [e for _, e, _ in notes]\n",
        "    if dummy_offsets and len(note_onsets) > 0:\n",
        "        note_offsets = note_onsets[1:] + [note_onsets[-1] + 1]\n",
        "    intervals = np.stack([note_onsets, note_offsets], axis = 1).astype(np.float64)\n",
        "    pitches = np.array([p for _, _, p in notes], dtype = np.int64)\n",
        "    return intervals, pitches\n",
        "\n",
        "\n",
        "def extract_notes(ref_midi_data, est_midi_data):\n",
        "    #ref_midi_data = pretty_midi.PrettyMIDI(ref_midi_file)\n",
        "    #est_midi_data = pretty_midi.PrettyMIDI(est_midi_file)\n",
        "    ref_midi_data = copy.deepcopy(ref_midi_data)\n",
        "    est_midi_data = copy.deepcopy(est_midi_data)\n",
        "\n",
        "    est_midi_data = trim_midi(ref_midi_data, est_midi_data)\n",
        "\n",
        "    ref_intervals, ref_pitches = midi_to_mir_eval(ref_midi_data, dummy_offsets = False)\n",
        "    est_intervals, est_pitches = midi_to_mir_eval(est_midi_data, dummy_offsets = False)\n",
        "\n",
        "    return ref_intervals, ref_pitches, est_intervals, est_pitches\n",
        "\n",
        "def mir_eval_onset_prf(ref_intervals, ref_pitches, est_intervals, est_pitches):\n",
        "    m_to_f = lambda m: 440.0 * np.power(2, (m.astype(np.float32) - 69) / 12)\n",
        "    p, r, f1, _ = mir_eval.transcription.precision_recall_f1_overlap(\n",
        "            ref_intervals,\n",
        "            m_to_f(ref_pitches),\n",
        "            est_intervals,\n",
        "            m_to_f(est_pitches),\n",
        "            onset_tolerance = EVAL_TOLERANCE,\n",
        "            pitch_tolerance = 1.0,\n",
        "            offset_ratio = None,\n",
        "        )\n",
        "    return p, r, f1\n",
        "\n",
        "\n",
        "def evaluate(ref_intervals, ref_pitches, est_intervals, est_pitches):\n",
        "    octaves = list(range(-OCTAVE_INVARIANT_RADIUS, OCTAVE_INVARIANT_RADIUS + 1))\n",
        "    ps = []\n",
        "    rs = []\n",
        "    f1s = []\n",
        "    for o in octaves:\n",
        "        p, r, f1 = mir_eval_onset_prf(\n",
        "            ref_intervals,\n",
        "            (o * 12) + ref_pitches,\n",
        "            est_intervals,\n",
        "            est_pitches\n",
        "        )\n",
        "        ps.append(p)\n",
        "        rs.append(r)\n",
        "        f1s.append(f1)\n",
        "\n",
        "    best_octave_idx = np.argmax(f1s)\n",
        "    return (\n",
        "        ps[best_octave_idx],\n",
        "        rs[best_octave_idx],\n",
        "        f1s[best_octave_idx]\n",
        "    )"
      ],
      "metadata": {
        "id": "3LOqerC01UGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory=\"/content/drive/MyDrive/MLSP_PROJECT/\"\n",
        "json_file=\"train_valid_test_keys.json\"\n",
        "train_dataset=AudioDataset(directory,json_file,\"TRAIN\")\n",
        "validation_dataset=AudioDataset(directory,json_file,\"VALID\")\n",
        "test_dataset=AudioDataset(directory,json_file,\"TEST\")"
      ],
      "metadata": {
        "id": "NrqTiXIysTz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][2]"
      ],
      "metadata": {
        "id": "KmJS1bW9sUVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc4978f-eb79-454c-8369-003d4a586939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pretty_midi.pretty_midi.PrettyMIDI at 0x7a80c13c3040>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_notes(train_dataset[0][2])%12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAZvuNFNyPwO",
        "outputId": "ed9d946d-8c6d-402b-eefb-4c9fba9f1aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  2,  4,  5,  7,  9, 11,  0,  0, 11,  9,  7,  5,  4,  2,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_pitches=[]\n",
        "\n",
        "for i in range(test_dataset.__len__()):\n",
        "  ground_truth_pitches.append(get_notes(test_dataset[i][2])%12)\n",
        "  if i%50==0:\n",
        "    print(\"Processing files:\", i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ_3_gLy0jg9",
        "outputId": "c716a8c8-f755-463a-b487-f3ef69284119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files: 0\n",
            "Processing files: 50\n",
            "Processing files: 100\n",
            "Processing files: 150\n",
            "Processing files: 200\n",
            "Processing files: 250\n",
            "Processing files: 300\n",
            "Processing files: 350\n",
            "Processing files: 400\n",
            "Processing files: 450\n",
            "Processing files: 500\n",
            "Processing files: 550\n",
            "Processing files: 600\n",
            "Processing files: 650\n",
            "Processing files: 700\n",
            "Processing files: 750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ground_truth_pitches.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHkrtRkguJgN",
        "outputId": "1952f57b-139b-4ea9-9237-11c18ac81ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onsets_dir=\"/content/drive/MyDrive/MLSP_PROJECT/corrected_onsets/\"\n",
        "directory=\"/content/drive/MyDrive/MLSP_PROJECT/\"\n",
        "json_file=\"train_valid_test_keys.json\"\n",
        "with open(directory+json_file, 'r') as f:\n",
        "  data = json.load(f)\n",
        "  file_list = data[\"TEST\"]"
      ],
      "metadata": {
        "id": "KsRUricVtCWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.loadtxt(onsets_dir+\"TEST/\"+file_list[0]+\".txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHIATRhs2ICu",
        "outputId": "629bb0aa-8aa4-4f15-93b9-c9ed73d2cb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.20897959,  0.63854875,  1.05650794,  1.4860771 ,  1.91564626,\n",
              "        2.75156463,  3.18113379,  3.68036281,  4.56272109,  5.46829932,\n",
              "        7.09369615,  7.54648526,  7.99927438,  8.45206349,  8.91646259,\n",
              "        9.76399093, 10.19356009, 10.65795918])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#These are corrected onsets\n",
        "test_onsets=[]\n",
        "for i in range(file_list.__len__()):\n",
        "  test_onsets.append(np.loadtxt(onsets_dir+\"TEST/\"+file_list[i]+\".txt\"))\n",
        "  if i%50==0:\n",
        "    print(\"Processing files:\", i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EDClZW50_lf",
        "outputId": "65ee0161-1e25-44b5-965c-3dbab4fd80bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files: 0\n",
            "Processing files: 50\n",
            "Processing files: 100\n",
            "Processing files: 150\n",
            "Processing files: 200\n",
            "Processing files: 250\n",
            "Processing files: 300\n",
            "Processing files: 350\n",
            "Processing files: 400\n",
            "Processing files: 450\n",
            "Processing files: 500\n",
            "Processing files: 550\n",
            "Processing files: 600\n",
            "Processing files: 650\n",
            "Processing files: 700\n",
            "Processing files: 750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_onsets[8].__len__())\n",
        "print(ground_truth_pitches[8].__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t3ncXc4CyCh",
        "outputId": "a09d08f2-b6f4-4ba9-8774-5cd03fbda6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n",
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa_onsets=[]\n",
        "for k in range(test_dataset.__len__()):\n",
        "  y,sr=test_dataset[k][:-1]\n",
        "  librosa_onsets.append(librosa.onset.onset_detect(y=np.nan_to_num(nr.reduce_noise(y=y, sr=sr)), sr=sr, units='time'))\n",
        "  if k%50==0:\n",
        "    print(\"Processing files:\", k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmyRhCskx54D",
        "outputId": "1381545d-c64f-4443-c378-37c7c0acb601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files: 0\n",
            "Processing files: 50\n",
            "Processing files: 100\n",
            "Processing files: 150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/noisereduce/spectralgate/nonstationary.py:71: RuntimeWarning: invalid value encountered in divide\n",
            "  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files: 200\n",
            "Processing files: 250\n",
            "Processing files: 300\n",
            "Processing files: 350\n",
            "Processing files: 400\n",
            "Processing files: 450\n",
            "Processing files: 500\n",
            "Processing files: 550\n",
            "Processing files: 600\n",
            "Processing files: 650\n",
            "Processing files: 700\n",
            "Processing files: 750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "est_pitches=[]\n",
        "\n",
        "for k in range(test_dataset.__len__()):\n",
        "  y,sr=test_dataset[k][:-1]\n",
        "  #y_harm = librosa.effects.harmonic(y=y, margin=50)\n",
        "  #chroma_cq = librosa.feature.chroma_cqt(y=y_harm, sr=sr)\n",
        "  chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "  time_bins=(librosa_onsets[k]*chroma_cq.shape[1]/(y.shape[0]/sr)).astype(int)\n",
        "  time_bins=np.hstack([time_bins,chroma_cq.shape[1]])\n",
        "\n",
        "  #print(time_bins)\n",
        "  est_pitch=[]\n",
        "  #pitches.append(chroma_cq[:,0:time_bins[0]])\n",
        "  for t in range(time_bins.shape[0]-1):\n",
        "    if time_bins[t+1]-time_bins[t]!=0:\n",
        "      pitch=np.argmax(chroma_cq[:,time_bins[t]:time_bins[t+1]],axis=0)\n",
        "      most_frequent_pitch=np.argmax(np.bincount(pitch)) #Most frequent row (note)\n",
        "    else:\n",
        "      pitch=np.argmax(chroma_cq[:,time_bins[t]],axis=0) #This is the case where two consecutive time bins are the same\n",
        "      most_frequent_pitch=np.argmax(pitch)\n",
        "    #print(time_bins[t],time_bins[t+1])\n",
        "    #print(t)\n",
        "\n",
        "    est_pitch.append(most_frequent_pitch)\n",
        "  est_pitches.append(np.array(est_pitch))\n",
        "  #print(k)\n",
        "  if k%50==0:\n",
        "    print(\"Processing data:\",k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHdy1Djw4GSk",
        "outputId": "dd3c6d00-c4c8-4863-b4a8-c2617ef3a563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data: 0\n",
            "Processing data: 50\n",
            "Processing data: 100\n",
            "Processing data: 150\n",
            "Processing data: 200\n",
            "Processing data: 250\n",
            "Processing data: 300\n",
            "Processing data: 350\n",
            "Processing data: 400\n",
            "Processing data: 450\n",
            "Processing data: 500\n",
            "Processing data: 550\n",
            "Processing data: 600\n",
            "Processing data: 650\n",
            "Processing data: 700\n",
            "Processing data: 750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean precision, recall and F1-score, when comparing Librosa's onsets and chroma features for pitch estimation vs corrected onsets + ground truth pitches**"
      ],
      "metadata": {
        "id": "POZk-Biur4MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#There are some onsets in the corrected onsets that repeat. Mier eval cannot handle this. I should get rid of these repeated onsets, but also to their corresponding ground truth note.\n",
        "precision,recall,f1_score=[],[],[]\n",
        "for k in range(test_dataset.__len__()):\n",
        "  y,sr=test_dataset[k][:-1]\n",
        "  ground_truth_onset,ixs=np.unique(test_onsets[k],return_index=True)\n",
        "\n",
        "  ref_intervals=np.vstack([ground_truth_onset,np.append(ground_truth_onset[:-1]+np.diff(ground_truth_onset),y.shape[0]/sr)]).T\n",
        "  est_intervals=np.vstack([librosa_onsets[k],np.append(librosa_onsets[k][:-1]+np.diff(librosa_onsets[k]),y.shape[0]/sr)]).T\n",
        "\n",
        "  pr,rc,f1=evaluate(ref_intervals, ground_truth_pitches[k][ixs], est_intervals, est_pitches[k])\n",
        "  #print(k)\n",
        "  precision.append(pr)\n",
        "  recall.append(rc)\n",
        "  f1_score.append(f1)\n",
        "  if k%50==0:\n",
        "    print(\"Processing files:\", k)\n",
        "print(np.mean(precision),np.mean(recall),np.mean(f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iuN9OSd7-5A",
        "outputId": "bc66d1f3-6787-4ab0-b6ec-f670f9f3189a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files: 0\n",
            "Processing files: 50\n",
            "Processing files: 100\n",
            "Processing files: 150\n",
            "Processing files: 200\n",
            "Processing files: 250\n",
            "Processing files: 300\n",
            "Processing files: 350\n",
            "Processing files: 400\n",
            "Processing files: 450\n",
            "Processing files: 500\n",
            "Processing files: 550\n",
            "Processing files: 600\n",
            "Processing files: 650\n",
            "Processing files: 700\n",
            "Processing files: 750\n",
            "0.45183269476589943 0.6302134874139907 0.5185815176993933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean precision, recall and F1-score, when comparing Librosa's onsets and chroma features for pitch vs original onsets + ground truth pitches**"
      ],
      "metadata": {
        "id": "061h55h3sHM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision,recall,f1_score=[],[],[]\n",
        "for k in range(test_dataset.__len__()):\n",
        "  y,sr=test_dataset[k][:-1]\n",
        "  ref_intervals=get_onset_offset(test_dataset[k][2]) #ORIGINAL NON-CORRECTED ONSETS/OFFSETS\n",
        "  est_intervals=np.vstack([librosa_onsets[k],np.append(librosa_onsets[k][:-1]+np.diff(librosa_onsets[k]),y.shape[0]/sr)]).T\n",
        "\n",
        "  pr,rc,f1=evaluate(ref_intervals, ground_truth_pitches[k], est_intervals, est_pitches[k])\n",
        "  #print(k)\n",
        "  precision.append(pr)\n",
        "  recall.append(rc)\n",
        "  f1_score.append(f1)\n",
        "  if k%50==0:\n",
        "    print(\"Processing files:\", k)\n",
        "print(np.mean(precision),np.mean(recall),np.mean(f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQtRxWJIZ_GH",
        "outputId": "ac0b8960-1f62-4921-bdd4-7fc2c59e3f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing files: 0\n",
            "Processing files: 50\n",
            "Processing files: 100\n",
            "Processing files: 150\n",
            "Processing files: 200\n",
            "Processing files: 250\n",
            "Processing files: 300\n",
            "Processing files: 350\n",
            "Processing files: 400\n",
            "Processing files: 450\n",
            "Processing files: 500\n",
            "Processing files: 550\n",
            "Processing files: 600\n",
            "Processing files: 650\n",
            "Processing files: 700\n",
            "Processing files: 750\n",
            "0.031050961668413646 0.04442319376700016 0.0359395952273152\n"
          ]
        }
      ]
    }
  ]
}